{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "from typing import Dict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tmu.models.classification.vanilla_classifier import TMClassifier\n",
    "from tmu.preprocessing.standard_binarizer.binarizer import StandardBinarizer\n",
    "from tmu.data import TMUDataset\n",
    "from tmu.composite.components.base import TMComponent\n",
    "from tmu.composite.composite import TMComposite\n",
    "from tmu.composite.config import TMClassifierConfig\n",
    "from tmu.composite.callbacks.base import TMCompositeCallback\n",
    "import logging\n",
    "import scipy.io as sio\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n",
    "import sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from TM_mat_comp.components.domf_component import DomfComponent\n",
    "from TM_mat_comp.components.fft_component import FftComponent\n",
    "from TM_mat_comp.components.std_component import StdComponent\n",
    "from TM_mat_comp.components.psd_component import PsdComponent\n",
    "\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.INFO)\n",
    "logging.getLogger('PIL.PngImagePlugin').setLevel(logging.INFO)\n",
    "_LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(TMUDataset):\n",
    "    def __init__(self, dataset_name, use_cache=False):\n",
    "        super().__init__()\n",
    "        self.dataset_name = dataset_name\n",
    "        self.use_cache = use_cache\n",
    "        self.classes = {'pulse':0,'31':1,'12':2,'sine':3,'34':4,'11':5,'chirp_uneven':6,'not_sweep':7,'32':8,'40':9}\n",
    "        # {\"11\": 0, \"12\": 1, \"31\": 2, \"32\": 3, \"34\": 4, \"40\": 5, \"chirp_uneven\": 6, \"not_sweep\": 7, \"pulse\": 8, \"sine\": 9}\n",
    "        self.cache_dir = './cache'\n",
    "        # self.w = w\n",
    "        # self.h = h\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "\n",
    "    def _cache_path(self, dataset_type):\n",
    "        return os.path.join(self.cache_dir, f\"{self.dataset_name}_{dataset_type}_{self.w}x{self.h}.pkl\")\n",
    "\n",
    "    def _load_from_cache(self, dataset_type):\n",
    "        path = self._cache_path(dataset_type)\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        return None\n",
    "\n",
    "    def _save_to_cache(self, dataset_type, data):\n",
    "        path = self._cache_path(dataset_type)\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def _transform(self, name, dataset):\n",
    "        return dataset\n",
    "\n",
    "    def _retrieve_dataset(self) -> Dict[str, np.ndarray]:\n",
    "        dataset = {}\n",
    "        for dtype in ['train', 'test']:\n",
    "            if self.use_cache:\n",
    "                cached_data = self._load_from_cache(dtype)\n",
    "                if cached_data:\n",
    "                    dataset.update(cached_data)\n",
    "                    continue\n",
    "            data = self.create_train_data(dtype)\n",
    "            if self.use_cache:\n",
    "                self._save_to_cache(dtype, {f'x_{dtype}': data[0], f'y_{dtype}': data[1]})\n",
    "            dataset[f'x_{dtype}'] = data[0]\n",
    "            dataset[f'y_{dtype}'] = data[1]\n",
    "        return dataset\n",
    " \n",
    "\n",
    "    def create_train_data(self, dataset_type): \n",
    "        X_data = []\n",
    "        y_data = []\n",
    "        main_path = os.path.join('/data', self.dataset_name) \n",
    "\n",
    "        data_dir = os.path.join(main_path, dataset_type)\n",
    "\n",
    "        for class_folder in os.listdir(data_dir):\n",
    "            class_dir = os.path.join(data_dir, class_folder)\n",
    "            for j in os.listdir(class_dir)[0:5]:\n",
    "                class_path = os.path.join(class_dir, j)\n",
    "                mat_data = sio.loadmat(class_path)\n",
    "                X_data.append(mat_data)\n",
    "                y_data.append(self.classes.get(class_folder))\n",
    "\n",
    "        return np.array(X_data), np.array(y_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Component 0: DomfComponent:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Component 0: DomfComponent:  50%|█████     | 1/2 [00:00<00:00,  5.36it/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "Component 0: DomfComponent: 100%|██████████| 2/2 [00:00<00:00,  5.53it/s]\n",
      "\n",
      "Component 2: StdComponent: 100%|██████████| 2/2 [00:00<00:00,  4.15it/s]\n",
      "Component 0: DomfComponent: 100%|██████████| 2/2 [00:00<00:00,  3.80it/s]\n",
      "Component 1: FftComponent: 100%|██████████| 2/2 [00:00<00:00,  3.81it/s]\n",
      "Component 3: PsdComponent: 100%|██████████| 2/2 [00:00<00:00,  3.85it/s]\n"
     ]
    }
   ],
   "source": [
    "class TMCompositeEvaluationCallback(TMCompositeCallback):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.best_acc = 0.0\n",
    "        self.data = data\n",
    "\n",
    "    def on_epoch_end(self, composite, epoch, logs=None):\n",
    "        preds = composite.predict(data=self.data)\n",
    "        acc = (preds == self.data[\"Y\"]).mean()\n",
    "        _LOGGER.info(f\"Epoch {epoch} - Accuracy: {acc:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # General hyperparameters\n",
    "    epochs = 2\n",
    "    device = \"CPU\"\n",
    "    size_w, size_h = 80, 80\n",
    "    multiprocessing_mode = True\n",
    "    p_w, p_h = 10, 10\n",
    "    \n",
    "    \n",
    "    \n",
    "    data = DataProcessor(\"data/\", use_cache=False).get()\n",
    "    X_train_org = data[\"x_train\"]\n",
    "    Y_train = data[\"y_train\"]\n",
    "    X_test_org = data[\"x_test\"]\n",
    "    Y_test = data[\"y_test\"]\n",
    "\n",
    "    data_train = dict(\n",
    "        X=X_train_org,\n",
    "        Y=Y_train\n",
    "    )\n",
    "\n",
    "    data_test = dict(\n",
    "        X=X_test_org,\n",
    "        Y=Y_test\n",
    "    )\n",
    "\n",
    "\n",
    "    composite_model = TMComposite(\n",
    "        use_multiprocessing=multiprocessing_mode,\n",
    "        components=[\n",
    "            DomfComponent(TMClassifier, TMClassifierConfig(\n",
    "                number_of_clauses=10,\n",
    "                T=5,\n",
    "                s=10,\n",
    "                max_included_literals=32,\n",
    "                weighted_clauses=True,\n",
    "                patch_dim=(p_w, p_h),\n",
    "                platform=device\n",
    "            ), epochs=epochs, target_size=(size_w, size_h)),\n",
    "\n",
    "            FftComponent(TMClassifier, TMClassifierConfig(\n",
    "                number_of_clauses=10,\n",
    "                T=5,\n",
    "                s=10,\n",
    "                max_included_literals=32,\n",
    "                weighted_clauses=True,\n",
    "                patch_dim=(p_w, p_h),\n",
    "                platform=device\n",
    "            ), epochs=epochs, target_size=(size_w, size_h)),\n",
    "\n",
    "            StdComponent(TMClassifier, TMClassifierConfig(\n",
    "                number_of_clauses=10,\n",
    "                T=5,\n",
    "                s=10,\n",
    "                max_included_literals=32,\n",
    "                weighted_clauses=True,\n",
    "                patch_dim=(p_w, p_h),\n",
    "                platform=device\n",
    "            ), epochs=epochs, target_size=(size_w, size_h)),\n",
    "\n",
    "            PsdComponent(TMClassifier, TMClassifierConfig(\n",
    "                number_of_clauses=10,\n",
    "                T=5,\n",
    "                s=10,\n",
    "                max_included_literals=32,\n",
    "                weighted_clauses=True,\n",
    "                patch_dim=(p_w, p_h),\n",
    "                platform=device\n",
    "            ), epochs=epochs, target_size=(size_w, size_h)),\n",
    "            \n",
    "        ])\n",
    "    \n",
    "    # Train the composite model\n",
    "    composite_model.fit(\n",
    "        data=data_train,\n",
    "        callbacks=[\n",
    "            TMCompositeEvaluationCallback(data=data_test)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 6 6 6 6 6 7 7\n",
      " 7 7 7 8 8 8 8 8 9 9 9 9 9]\n",
      "[7 7 7 7 7 0 8 0 4 7 0 7 7 7 7 7 7 7 7 7 7 0 7 7 7 9 0 0 7 7 0 8 4 4 8 4 4\n",
      " 0 7 7 3 3 3 3 3 9 7 7 9 9]\n",
      "composite Accuracy: 10.0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 9 9 0 0 0 0 0 0 0 0 0 9 0\n",
      " 0 0 0 3 3 3 3 3 9 0 0 9 9]\n",
      "DomfComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) Accuracy: 18.0\n",
      "[0 0 4 4 0 0 8 8 4 0 0 0 0 0 0 8 8 8 8 8 8 0 4 8 8 4 0 0 8 8 0 8 4 4 8 4 4\n",
      " 0 8 0 8 8 4 8 8 8 0 8 8 8]\n",
      "FftComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) Accuracy: 16.0\n",
      "[7 7 7 7 7 0 0 0 0 7 0 7 7 7 7 7 7 7 7 7 7 0 7 7 7 7 0 0 7 7 0 0 0 0 0 7 7\n",
      " 0 7 7 0 0 0 0 0 7 7 7 7 7]\n",
      "StdComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) Accuracy: 8.0\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 9 0 0 9 9]\n",
      "PsdComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) Accuracy: 16.0\n"
     ]
    }
   ],
   "source": [
    "preds = composite_model.predict(data=data_test)\n",
    "\n",
    "y_true = data_test[\"Y\"].flatten()\n",
    "print(y_true)\n",
    "for k, v in preds.items():\n",
    "    print(v)\n",
    "    print(f\"{k} Accuracy: %.1f\" % (100 * (v == y_true).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-19 07:42:24,221 - __main__ - INFO - composite cm : \n",
      "[[0 0 0 0 0 0 0 5 0 0]\n",
      " [2 0 0 0 1 0 0 1 1 0]\n",
      " [1 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0]\n",
      " [1 0 0 0 0 0 0 4 0 0]\n",
      " [2 0 0 0 0 0 0 2 0 1]\n",
      " [1 0 0 0 2 0 0 0 2 0]\n",
      " [1 0 0 0 2 0 0 2 0 0]\n",
      " [0 0 0 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 3]]\n",
      "2024-04-19 07:42:24,223 - __main__ - INFO - DomfComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) cm : \n",
      "[[5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [4 0 0 1 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0 0 0 1]\n",
      " [4 0 0 0 0 0 0 0 0 1]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 5 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 3]]\n",
      "2024-04-19 07:42:24,224 - __main__ - INFO - FftComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) cm : \n",
      "[[3 0 0 0 2 0 0 0 0 0]\n",
      " [2 0 0 0 1 0 0 0 2 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 5 0]\n",
      " [1 0 0 0 1 0 0 0 3 0]\n",
      " [2 0 0 0 1 0 0 0 2 0]\n",
      " [1 0 0 0 2 0 0 0 2 0]\n",
      " [2 0 0 0 2 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 0 4 0]\n",
      " [1 0 0 0 0 0 0 0 4 0]]\n",
      "2024-04-19 07:42:24,226 - __main__ - INFO - StdComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) cm : \n",
      "[[0 0 0 0 0 0 0 5 0 0]\n",
      " [4 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0]\n",
      " [1 0 0 0 0 0 0 4 0 0]\n",
      " [2 0 0 0 0 0 0 3 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 4 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0]]\n",
      "2024-04-19 07:42:24,227 - __main__ - INFO - PsdComponent-TMClassifier-number_of_clauses=10-T=5-s=10.0-max_included_literals=32-platform=CPU-weighted_clauses=True-patch_dim=(10, 10)) cm : \n",
      "[[5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "for k, v in preds.items():\n",
    "    cm = confusion_matrix(y_true, v)\n",
    "    _LOGGER.info(f\"{k} cm : \\n{cm}\")\n",
    "    # if(k == \"composite\"):\n",
    "    #     _LOGGER.info(f\"{k} cm : \\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
